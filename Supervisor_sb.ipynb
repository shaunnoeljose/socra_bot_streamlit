{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39c888c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c7bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MESSAGES_IN_CONTEXT = 10\n",
    "# Defining the class of the agent\n",
    "class Agent(TypedDict):\n",
    "    \"\"\"\n",
    "    Defines the state of the agent in the conversation\n",
    "    messages: A list of chat messages exchanged so far.\n",
    "    difficulty_level: The current difficulty level of questions (e.g., 'beginner', 'intermediate', 'advanced').\n",
    "    user_struggle_count: Counter for consecutive times the user struggles.\n",
    "    topic: The current Python topic being discussed.\n",
    "    sub_topic: The specific sub-topic within the main topic.\n",
    "    mcq_active: Boolean indicating if an MCQ is currently active.\n",
    "    mcq_question: The active MCQ question text.\n",
    "    mcq_options: List of options for the active MCQ.\n",
    "    mcq_correct_answer: The correct answer for the active MCQ.\n",
    "    agent_thought: The last thought process articulated by the Socratic agent.\n",
    "    next_node: str # The next node the supervisor has decided to route to\n",
    "    tool_input: dict # Input arguments for the tool if a tool is routed to        \n",
    "    \"\"\"\n",
    "    \n",
    "    messages: Annotated[List[BaseMessage], add_messages] # Appends new messages to the list\n",
    "    difficulty_level: str\n",
    "    user_struggle_count: int\n",
    "    topic: str\n",
    "    sub_topic: str\n",
    "    mcq_active: bool\n",
    "    mcq_question: str\n",
    "    mcq_options: List[str]\n",
    "    mcq_correct_answer: str\n",
    "    agent_thought: str\n",
    "    next_node: str\n",
    "    tool_input: dict\n",
    "\n",
    "# Initialize the Gemini LLM for the Socratic Agent\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac41b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the tools performing the tasks\n",
    "\n",
    "@tool\n",
    "def code_analysis_agent(code:str)->str:\n",
    "    \"\"\"\n",
    "    Analyzes the provided Python code, identifies issues, suggests improvements, and provides feedback. \n",
    "    Use this when the user provides code and asks for review or debugging. The output will be used by the Socratic agent to ask questions.\n",
    "    \"\"\"\n",
    "    return f\"Code Analysis Result: For the code snippet '{code}', a potential area to explore is its efficiency in handling large inputs, or error handling. Also, consider adding comments for clarity.\"\n",
    "\n",
    "@tool\n",
    "def code_explanation_agent(concept: str) -> str:\n",
    "    \"\"\"\n",
    "    Explains a given Python concept, function, keyword, or error message in detail.\n",
    "    Use this when the user asks for an explanation of something.\n",
    "    The output is raw explanation, which the Socratic agent will then use to ask questions.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM specialized in explanations.\n",
    "    return f\"Explanation Result: The concept of '{concept}' in Python generally refers to [brief factual summary]. For instance, if it's about 'loops', it describes repetitive execution. If it's 'objects', it's about data and behavior bundling.\"\n",
    "\n",
    "@tool\n",
    "def challenge_generator_agent(topic: str, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a Python coding challenge or a fill-in-the-blanks exercise based on the specified topic and difficulty.\n",
    "    Use this when the user requests a challenge.\n",
    "    The output is the challenge, which the Socratic agent will present.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM or a challenge generation service.\n",
    "    # logger.info(f\"Executing Challenge Generation for: {topic}, Difficulty: {difficulty}\") # Uncomment when logger is ready\n",
    "    return f\"Challenge Result: For '{topic}' at '{difficulty}' difficulty: 'Write a Python function that takes a list of numbers and returns the sum of all **odd** numbers.' How would you approach solving this?\"\n",
    "\n",
    "@tool\n",
    "def mcq_agent(topic: str, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a multiple-choice question (MCQ) on a given Python topic and difficulty level.\n",
    "    The output will be a JSON string containing the question, options, and correct answer.\n",
    "    This tool is called when the Socratic agent decides to test understanding via MCQ.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM specifically for MCQ generation.\n",
    "    # logger.info(f\"Executing MCQ Generation for: {topic}, Difficulty: {difficulty}\") # Uncomment when logger is ready\n",
    "    mcq_data = {\n",
    "        \"question\": f\"Which of the following operations would lead to an `IndentationError` in Python?\",\n",
    "        \"options\": [\"A) Missing a colon after a function definition\", \"B) Inconsistent use of spaces and tabs for indentation\", \"C) Using a reserved keyword as a variable name\", \"D) Forgetting a closing parenthesis\"],\n",
    "        \"correct_answer\": \"B\"\n",
    "    }\n",
    "    return json.dumps(mcq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69624cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facing_tools = [code_analysis_agent, code_explanation_agent, challenge_generator_agent, mcq_agent]\n",
    "\n",
    "@tool\n",
    "def route_to_socratic_question(query: str = None) -> str:\n",
    "    \"\"\"Routes the conversation to the main Socratic Questioning agent for general teaching or follow-up.\n",
    "    This is the default route for general queries, concept discussions, and after tool outputs.\n",
    "    Optionally includes a follow-up query for the Socratic agent if the intent is specific.\n",
    "    \"\"\"\n",
    "    return \"socratic_question\"\n",
    "\n",
    "@tool\n",
    "def route_to_code_analysis(code: str) -> str:\n",
    "    \"\"\"Routes to the Code Analysis agent for debugging or code review. Requires the code snippet.\"\"\"\n",
    "    return \"code_analysis\"\n",
    "\n",
    "@tool\n",
    "def route_to_code_explanation(concept: str) -> str:\n",
    "    \"\"\"Routes to the Code Explanation agent to explain a specific concept, keyword, or error. Requires the concept.\"\"\"\n",
    "    return \"code_explanation\"\n",
    "\n",
    "@tool\n",
    "def route_to_challenge_generator(topic: str = None, difficulty: str = None) -> str:\n",
    "    \"\"\"Routes to the Challenge Generator agent to create a coding challenge. Optionally specify topic and difficulty.\"\"\"\n",
    "    return \"challenge_generator\"\n",
    "\n",
    "@tool\n",
    "def route_to_mcq_generator(topic: str = None, difficulty: str = None) -> str:\n",
    "    \"\"\"Routes to the MCQ Generator agent to create a multiple-choice question. Optionally specify topic and difficulty.\"\"\"\n",
    "    return \"mcq_generator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "383a8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all internal routing tools available to the Supervisor\n",
    "supervisor_routing_tools = [\n",
    "    route_to_socratic_question,\n",
    "    route_to_code_analysis,\n",
    "    route_to_code_explanation,\n",
    "    route_to_challenge_generator,\n",
    "    route_to_mcq_generator\n",
    "]\n",
    "\n",
    "# Supervisor Agent Setup\n",
    "supervisor_system_prompt = \"\"\"\n",
    "You are a highly intelligent routing agent for a Socratic Python Tutor. Your task is to analyze\n",
    "the user's last message and the conversation history to determine the most appropriate next step\n",
    "in the learning process.\n",
    "\n",
    "You have access to several internal routing tools. Call exactly one of these tools to specify\n",
    "which specialized agent or flow should handle the user's request.\n",
    "\n",
    "Here are your routing rules:\n",
    "-   **Default:** For general questions, learning new topics, or continuing a Socratic dialogue, use `route_to_socratic_question`. This should be your most frequent choice.\n",
    "-   **Code Analysis:** If the user provides Python code and asks for debugging, feedback, review, or analysis, use `route_to_code_analysis` and pass the code.\n",
    "-   **Code Explanation:** If the user explicitly asks for an explanation of a specific Python concept, keyword, function, or error message, use `route_to_code_explanation` and pass the concept.\n",
    "-   **Challenge/Exercise:** If the user explicitly asks for a coding challenge, exercise, or fill-in-the-blanks, use `route_to_challenge_generator`.\n",
    "-   **MCQ:** If the user asks for a multiple-choice question or you determine an MCQ is a good way to test their understanding, use `route_to_mcq_generator`.\n",
    "\n",
    "Pay close attention to keywords and the overall intent. Your response MUST be a tool call.\n",
    "\n",
    "Current difficulty level: {difficulty_level}\n",
    "Current topic: {topic}\n",
    "Current sub-topic: {sub_topic}\n",
    "\"\"\"\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", supervisor_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "supervisor_runnable = supervisor_prompt | llm.bind_tools(supervisor_routing_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65a64dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Socratic Agent Setup (This is our main Socratic Questioning LLM)\n",
    "socratic_system_prompt = \"\"\"\n",
    "You are a Socratic Python programming tutor. Your goal is to guide the user to discover answers\n",
    "and understand concepts through thoughtful questions, rather than directly providing solutions.\n",
    "\n",
    "Here are your core principles:\n",
    "1.  **Ask Questions:** Always respond with a question, unless explicitly providing feedback on code or an MCQ answer.\n",
    "2.  **Socratic Method:** Break down complex problems into smaller, manageable questions.\n",
    "3.  **Encourage Exploration:** Prompt the user to experiment, research, or think critically.\n",
    "4.  **Adapt to User Understanding:**\n",
    "    * **Struggle Detection:** If the user seems confused, provides incorrect answers, or asks for direct solutions, simplify your questions, rephrase, or offer a hint.\n",
    "    * **Progression:** If the user demonstrates understanding, subtly move to a slightly more advanced sub-concept or a related new topic. Avoid repetitive questioning on the same point.\n",
    "5.  **Interpret Tool Outputs Socratically:** If a tool provides information (e.g., Code Analysis Result, Explanation Result, Challenge Result), your task is to *process that information* and turn it into a Socratic question or guided step for the user. Do not just relay the tool's output directly.\n",
    "6.  **Maintain Context:** Keep track of the current topic and sub-topic.\n",
    "7.  **Be Patient and Encouraging:** Foster a positive learning environment.\n",
    "8.  **ReAct Architecture (Internal Thought):** Before responding, articulate your thought process. Start your response with \"Thought: [Your reasoning here]\". This thought will be logged but not shown to the user. Then, proceed with your Socratic question.\n",
    "\n",
    "Current difficulty level: {difficulty_level}\n",
    "Current topic: {topic}\n",
    "Current sub-topic: {sub_topic}\n",
    "User struggle count: {user_struggle_count}\n",
    "MCQ active: {mcq_active}\n",
    "\"\"\"\n",
    "\n",
    "socratic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", socratic_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "socratic_agent_runnable = socratic_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2426ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_supervisor(state: Agent):\n",
    "    \"\"\"\n",
    "    Node for the supervisor to determine the next action/agent based on user intent.\n",
    "    \"\"\"\n",
    "    # logger.info(\"Supervisor node activated.\") # Uncomment when logger is ready\n",
    "    messages = state[\"messages\"][-MAX_MESSAGES_IN_CONTEXT:] # Apply truncation here\n",
    "    # Pass the full state to the prompt for contextual awareness in routing\n",
    "    response = supervisor_runnable.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"difficulty_level\": state[\"difficulty_level\"],\n",
    "        \"user_struggle_count\": state[\"user_struggle_count\"],\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"sub_topic\": state[\"sub_topic\"]\n",
    "    })\n",
    "\n",
    "    # The supervisor is expected to call one of its internal routing tools.\n",
    "    # Extract the tool call and set the next_node and tool_input in the state.\n",
    "    if response.tool_calls:\n",
    "        tool_call = response.tool_calls[0] # Assuming supervisor calls one tool\n",
    "        next_node = tool_call.name.replace(\"route_to_\", \"\") # Extract node name (e.g., \"socratic_question\")\n",
    "        tool_input = tool_call.args\n",
    "        # logger.info(f\"Supervisor decided to route to: {next_node} with input: {tool_input}\") # Uncomment when logger is ready\n",
    "        return {\"messages\": [response], \"next_node\": next_node, \"tool_input\": tool_input}\n",
    "    else:\n",
    "        # Fallback if supervisor doesn't call a tool (shouldn't happen with proper prompt)\n",
    "        # Force it to the socratic question node\n",
    "        # logger.warning(\"Supervisor did not call a tool. Defaulting to socratic_question.\") # Uncomment when logger is ready\n",
    "        return {\"messages\": [response], \"next_node\": \"socratic_question\"}\n",
    "\n",
    "\n",
    "def socratic_question_node(state: Agent):\n",
    "    \"\"\"\n",
    "    Node for the main Socratic LLM to ask questions or interpret tool outputs.\n",
    "    \"\"\"\n",
    "    # logger.info(\"Socratic Question Node activated.\") # Uncomment when logger is ready\n",
    "    messages = state[\"messages\"][-MAX_MESSAGES_IN_CONTEXT:] # Apply truncation here\n",
    "    response = socratic_agent_runnable.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"difficulty_level\": state[\"difficulty_level\"],\n",
    "        \"user_struggle_count\": state[\"user_struggle_count\"],\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"sub_topic\": state[\"sub_topic\"],\n",
    "        \"mcq_active\": state[\"mcq_active\"]\n",
    "    })\n",
    "\n",
    "    # Extract thought (for logging)\n",
    "    thought = \"\"\n",
    "    if response.content and response.content.startswith(\"Thought:\"):\n",
    "        parts = response.content.split(\"Thought:\", 1)\n",
    "        if len(parts) > 1:\n",
    "            thought = parts[1].strip().split('\\n', 1)[0]\n",
    "\n",
    "    return {\"messages\": [response], \"agent_thought\": thought}\n",
    "\n",
    "\n",
    "def call_specialized_tool_node(state: Agent):\n",
    "    \"\"\"\n",
    "    Node to execute a specialized user-facing tool based on supervisor's decision.\n",
    "    \"\"\"\n",
    "    # logger.info(f\"Call Specialized Tool Node activated for {state['next_node']}\") # Uncomment when logger is ready\n",
    "    tool_name = state[\"next_node\"] # This comes from the supervisor's routing decision\n",
    "    tool_args = state[\"tool_input\"]\n",
    "\n",
    "    # Manually find and execute the tool function\n",
    "    tool_function = next((t for t in user_facing_tools if t.name == tool_name), None)\n",
    "\n",
    "    tool_output = \"\"\n",
    "    if tool_function:\n",
    "        try:\n",
    "            tool_output = tool_function(**tool_args)\n",
    "            # logger.info(f\"Tool '{tool_name}' executed. Output: {tool_output[:100]}...\") # Uncomment when logger is ready\n",
    "        except Exception as e:\n",
    "            tool_output = f\"Error executing tool {tool_name}: {e}\"\n",
    "            # logger.error(f\"Error executing tool {tool_name}: {e}\", exc_info=True) # Uncomment when logger is ready\n",
    "    else:\n",
    "        tool_output = f\"Error: Specialized tool '{tool_name}' not found.\"\n",
    "        # logger.error(f\"Specialized tool '{tool_name}' not found.\") # Uncomment when logger is ready\n",
    "\n",
    "    # Add the tool output as a ToolMessage to the conversation history\n",
    "    # The socratic_question_node will then process this and ask a question.\n",
    "    return {\"messages\": [ToolMessage(content=tool_output, name=tool_name)]}\n",
    "\n",
    "\n",
    "def generate_mcq_node(state: Agent):\n",
    "    \"\"\"\n",
    "    Node specifically for generating an MCQ via the mcq_agent tool.\n",
    "    This also handles setting the MCQ active state for main.py.\n",
    "    \"\"\"\n",
    "    # logger.info(\"MCQ Generation Node activated.\") # Uncomment when logger is ready\n",
    "    tool_name = \"mcq_agent\"\n",
    "    tool_args = state[\"tool_input\"] # Should contain topic and difficulty from supervisor\n",
    "\n",
    "    tool_function = next((t for t in user_facing_tools if t.name == tool_name), None)\n",
    "    mcq_raw_output = \"\"\n",
    "\n",
    "    if tool_function:\n",
    "        try:\n",
    "            mcq_raw_output = tool_function(**tool_args)\n",
    "            mcq_data = json.loads(mcq_raw_output)\n",
    "            state[\"mcq_active\"] = True\n",
    "            state[\"mcq_question\"] = mcq_data[\"question\"]\n",
    "            state[\"mcq_options\"] = mcq_data[\"options\"]\n",
    "            state[\"mcq_correct_answer\"] = mcq_data[\"correct_answer\"]\n",
    "            # logger.info(\"MCQ details updated in state.\") # Uncomment when logger is ready\n",
    "        except Exception as e:\n",
    "            mcq_raw_output = f\"Error generating MCQ: {e}\"\n",
    "            # logger.error(f\"Error generating MCQ: {e}\", exc_info=True) # Uncomment when logger is ready\n",
    "    \n",
    "    # Add a ToolMessage for the MCQ generation, which the Socratic LLM can interpret\n",
    "    # or simply for logging purposes in the graph flow.\n",
    "    return {\"messages\": [ToolMessage(content=mcq_raw_output, name=tool_name)], **state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18ae615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Define the Graph Edges (Conditional Logic) ---\n",
    "\n",
    "def route_supervisor_output(state: Agent):\n",
    "    \"\"\"\n",
    "    Conditional edge from the supervisor to determine the next node based on its decision.\n",
    "    \"\"\"\n",
    "    # logger.info(f\"Routing supervisor output. Next node: {state['next_node']}\") # Uncomment when logger is ready\n",
    "    if state[\"next_node\"] == \"socratic_question\":\n",
    "        return \"socratic_question_node\"\n",
    "    elif state[\"next_node\"] == \"mcq_generator\":\n",
    "        return \"generate_mcq_node\"\n",
    "    # All other specialized tools go through the generic tool calling node\n",
    "    elif state[\"next_node\"] in [\"code_analysis\", \"code_explanation\", \"challenge_generator\"]:\n",
    "        return \"call_specialized_tool_node\"\n",
    "    return \"socratic_question_node\" # Fallback to socratic question if unexpected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83b58b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(Agent)\n",
    "\n",
    "# Add nodes to the workflow.\n",
    "workflow.add_node(\"call_supervisor\", call_supervisor)\n",
    "workflow.add_node(\"socratic_question_node\", socratic_question_node) # Renamed from call_llm\n",
    "workflow.add_node(\"call_specialized_tool_node\", call_specialized_tool_node)\n",
    "workflow.add_node(\"generate_mcq_node\", generate_mcq_node)\n",
    "\n",
    "# Set the entry point for the graph.\n",
    "workflow.set_entry_point(\"call_supervisor\")\n",
    "\n",
    "# Define the edges.\n",
    "# From supervisor, route conditionally\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_supervisor\",\n",
    "    route_supervisor_output,\n",
    "    {\n",
    "        \"socratic_question_node\": \"socratic_question_node\",\n",
    "        \"call_specialized_tool_node\": \"call_specialized_tool_node\",\n",
    "        \"generate_mcq_node\": \"generate_mcq_node\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# After a specialized tool (other than MCQ), return to the socratic_question_node\n",
    "# for the Socratic LLM to interpret the tool's output and formulate a question.\n",
    "workflow.add_edge(\"call_specialized_tool_node\", \"socratic_question_node\")\n",
    "\n",
    "# After the socratic_question_node, the run ends. The main.py loop will then take user input.\n",
    "workflow.add_edge(\"socratic_question_node\", END)\n",
    "\n",
    "# After generating an MCQ, the run ends. Main.py handles the MCQ display and user input.\n",
    "workflow.add_edge(\"generate_mcq_node\", END)\n",
    "\n",
    "# Initialize MemorySaver\n",
    "# This will save conversation state to a local file system by default.\n",
    "# checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph into a runnable agent with the checkpointer.\n",
    "socratic_graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd8e7ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x75580f3af1d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socratic_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "377dacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Node: call_supervisor ---\n",
      "Node 'call_supervisor' Test FAILED: 'dict' object has no attribute 'name'\n",
      "--- End Node Test: call_supervisor ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12503/4231620347.py\", line 30, in _test_node_functionality\n",
      "    result_state_update = node_runnable.invoke(initial_state)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 377, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_12503/542529847.py\", line 20, in call_supervisor\n",
      "    next_node = tool_call.name.replace(\"route_to_\", \"\") # Extract node name (e.g., \"socratic_question\")\n",
      "                ^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "# --- Temporary LLM Connection Test ---\n",
    "# This function will be called once when the module is imported to test LLM connectivity.\n",
    "def _test_llm_connection():\n",
    "    print(\"\\n--- Testing LLM Connection (Temporary) ---\")\n",
    "    try:\n",
    "        test_message = HumanMessage(content=\"Say hi!\")\n",
    "        response = llm.invoke([test_message])\n",
    "        print(f\"LLM Test Response: {response.content}\")\n",
    "        print(\"LLM connection successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Connection Test FAILED: {e}\")\n",
    "        print(\"Please check your GOOGLE_API_KEY and network connection.\")\n",
    "    print(\"--- End LLM Connection Test ---\\n\")\n",
    "\n",
    "# --- Temporary Node Functionality Test ---\n",
    "# This function allows testing individual nodes with a sample state.\n",
    "def _test_node_functionality(node_name: str, initial_state: Agent):\n",
    "    print(f\"\\n--- Testing Node: {node_name} ---\")\n",
    "    try:\n",
    "        # Get the node function from the workflow's nodes\n",
    "        # Access the runnable attribute to get the actual function\n",
    "        # This is the fix for 'StateNodeSpec' object is not callable\n",
    "        node_runnable = workflow.nodes[node_name].runnable\n",
    "\n",
    "        # Invoke the node's runnable with the provided initial state\n",
    "        # For nodes that are LLMChain or similar, invoke with a dict matching their input schema\n",
    "        # For simple functions, it might be direct call.\n",
    "        # Here, we assume the node_runnable expects the full state dict as input,\n",
    "        # which is how LangGraph nodes are typically defined.\n",
    "        result_state_update = node_runnable.invoke(initial_state)\n",
    "\n",
    "\n",
    "        print(f\"Node '{node_name}' executed successfully.\")\n",
    "        print(f\"Initial State (messages only): {[msg.content if hasattr(msg, 'content') else str(msg) for msg in initial_state['messages']]}\")\n",
    "        print(f\"Resulting State Update: {result_state_update}\")\n",
    "\n",
    "        # For nodes that return messages, let's print them\n",
    "        if 'messages' in result_state_update and result_state_update['messages']:\n",
    "            print(\"Messages returned by node:\")\n",
    "            for msg in result_state_update['messages']:\n",
    "                if isinstance(msg, BaseMessage):\n",
    "                    print(f\"  - Type: {msg.type}, Content: {msg.content[:50]}...\")\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        # Ensure tool_calls are correctly converted to ToolCall objects\n",
    "                        # This part of the debug print itself needs to be robust\n",
    "                        for tc in msg.tool_calls:\n",
    "                            if isinstance(tc, ToolCall):\n",
    "                                print(f\"    Tool Call: {tc.function.name} with args {tc.function.arguments}\")\n",
    "                            else:\n",
    "                                print(f\"    Raw Tool Call (still dict?): {tc}\")\n",
    "                else:\n",
    "                    print(f\"  - Raw: {msg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Node '{node_name}' Test FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for node errors\n",
    "    print(f\"--- End Node Test: {node_name} ---\\n\")\n",
    "\n",
    "\n",
    "# Call the LLM connection test immediately when this module is loaded\n",
    "# _test_llm_connection()\n",
    "\n",
    "# Example usage of the new node testing function (uncomment to test specific nodes)\n",
    "# Ensure your GOOGLE_API_KEY is set for LLM-based nodes.\n",
    "\n",
    "# Test call_supervisor node\n",
    "sample_supervisor_state = Agent(\n",
    "    messages=[HumanMessage(content=\"I need help with debugging this code: print('hello')\")],\n",
    "    difficulty_level=\"beginner\",\n",
    "    user_struggle_count=0,\n",
    "    topic=\"Python Basics\",\n",
    "    sub_topic=\"Introduction\",\n",
    "    mcq_active=False,\n",
    "    mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "    agent_thought=\"\", next_node=\"\", tool_input={}\n",
    ")\n",
    "_test_node_functionality(\"call_supervisor\", sample_supervisor_state)\n",
    "\n",
    "# Test socratic_question_node\n",
    "# sample_socratic_state = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"What are variables?\"), AIMessage(content=\"Thought: User asked about variables. I should ask a foundational question. What is your current understanding of variables in programming?\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Variables\",\n",
    "#     sub_topic=\"Definition\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\", next_node=\"\", tool_input={}\n",
    "# )\n",
    "# _test_node_functionality(\"socratic_question_node\", sample_socratic_state)\n",
    "\n",
    "# Test call_specialized_tool_node (e.g., code_analysis)\n",
    "# This requires the supervisor to have set next_node and tool_input previously.\n",
    "# For a direct test, we simulate that state.\n",
    "# sample_tool_state_code_analysis = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"debug this code: print('hello')\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Debugging\",\n",
    "#     sub_topic=\"Code Analysis\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\",\n",
    "#     next_node=\"code_analysis\", # Supervisor would set this\n",
    "#     tool_input={\"code\": \"def my_func():\\n    pass\"} # Supervisor would set this\n",
    "# )\n",
    "# _test_node_functionality(\"call_specialized_tool_node\", sample_tool_state_code_analysis)\n",
    "\n",
    "# Test generate_mcq_node\n",
    "# sample_mcq_state = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"Give me an MCQ on functions.\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Functions\",\n",
    "#     sub_topic=\"MCQ\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\",\n",
    "#     next_node=\"mcq_generator\", # Supervisor would set this\n",
    "#     tool_input={\"topic\": \"functions\", \"difficulty\": \"beginner\"} # Supervisor would set this\n",
    "# )\n",
    "# _test_node_functionality(\"generate_mcq_node\", sample_mcq_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdb53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing LLM Connection (Temporary) ---\n",
      "LLM Test Response: Hi!\n",
      "LLM connection successful!\n",
      "--- End LLM Connection Test ---\n",
      "\n",
      "\n",
      "--- Testing Node: call_supervisor ---\n",
      "Warning: Supervisor LLM returned a malformed tool call (name is None). Defaulting to socratic_question.\n",
      "Node 'call_supervisor' executed successfully.\n",
      "Initial State (messages only): [\"I need help with debugging this code: print('hello')\"]\n",
      "Resulting State Update: {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'route_to_code_analysis', 'arguments': '{\"code\": \"print(\\'hello\\')\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--06323891-6036-4975-a936-116d611be354-0', tool_calls=[{'name': 'route_to_code_analysis', 'args': {'code': \"print('hello')\"}, 'id': '51843dc3-a8f5-44f8-8e55-999f38e2e0f4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 12, 'total_tokens': 545, 'input_token_details': {'cache_read': 0}})], 'next_node': 'socratic_question'}\n",
      "Messages returned by node:\n",
      "  - Type: ai, Content: ...\n",
      "Node 'call_supervisor' Test FAILED: TypedDict does not support instance and class checks\n",
      "--- End Node Test: call_supervisor ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12503/3269865442.py\", line 442, in _test_node_functionality\n",
      "    if isinstance(tc, ToolCall):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/typing_extensions.py\", line 1102, in __subclasscheck__\n",
      "    raise TypeError('TypedDict does not support instance and class checks')\n",
      "TypeError: TypedDict does not support instance and class checks\n"
     ]
    }
   ],
   "source": [
    "# socratic_bot_logic.py\n",
    "\n",
    "import os\n",
    "from typing import List, TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, ToolCall\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.tools import tool # Ensure tool decorator is imported\n",
    "import json\n",
    "import uuid # Import uuid for generating unique IDs\n",
    "\n",
    "# Removed MemorySaver import\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Import the logging utility (assuming logger.py will be created later)\n",
    "# from logger import setup_logger\n",
    "# logger = setup_logger() # Uncomment when logger.py is ready\n",
    "\n",
    "# --- Configuration for Memory Management ---\n",
    "MAX_MESSAGES_IN_CONTEXT = 10 # Keep the last 10 messages in the context window\n",
    "# This includes both HumanMessage and AIMessage. Adjust as needed based on LLM context limits.\n",
    "\n",
    "# --- 1. Define the Agent State ---\n",
    "class SocraticAgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the Socratic agent's conversation.\n",
    "\n",
    "    Attributes:\n",
    "        messages: A list of chat messages exchanged so far.\n",
    "        difficulty_level: The current difficulty level of questions (e.g., 'beginner', 'intermediate', 'advanced').\n",
    "        user_struggle_count: Counter for consecutive times the user struggles.\n",
    "        topic: The current Python topic being discussed.\n",
    "        sub_topic: The specific sub-topic within the main topic.\n",
    "        mcq_active: Boolean indicating if an MCQ is currently active.\n",
    "        mcq_question: The active MCQ question text.\n",
    "        mcq_options: List of options for the active MCQ.\n",
    "        mcq_correct_answer: The correct answer for the active MCQ.\n",
    "        agent_thought: The last thought process articulated by the Socratic agent.\n",
    "        # Added for supervisor routing\n",
    "        next_node: str # The next node the supervisor has decided to route to\n",
    "        tool_input: dict # Input arguments for the tool if a tool is routed to\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y] # Appends new messages to the list\n",
    "    difficulty_level: str\n",
    "    user_struggle_count: int\n",
    "    topic: str\n",
    "    sub_topic: str\n",
    "    mcq_active: bool\n",
    "    mcq_question: str\n",
    "    mcq_options: List[str]\n",
    "    mcq_correct_answer: str\n",
    "    agent_thought: str\n",
    "    next_node: str\n",
    "    tool_input: dict\n",
    "\n",
    "\n",
    "# --- 2. Initialize the LLMs and Tools ---\n",
    "\n",
    "# Initialize the Gemini LLM (used for both Socratic and Supervisor agents)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
    "\n",
    "# --- Define User-Facing Simulated Agent Tools ---\n",
    "# These are the actual tools that will perform specific tasks.\n",
    "@tool\n",
    "def code_analysis_agent(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the provided Python code, identifies potential issues, suggests improvements,\n",
    "    and provides feedback. Use this when the user provides code and asks for review or debugging.\n",
    "    The output is raw analysis, which the Socratic agent will then use to ask questions.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM or a static analysis tool.\n",
    "    # logger.info(f\"Executing Code Analysis for: {code[:50]}...\") # Uncomment when logger is ready\n",
    "    return f\"Code Analysis Result: For the code snippet '{code}', a potential area to explore is its efficiency in handling large inputs, or error handling. Also, consider adding comments for clarity.\"\n",
    "\n",
    "@tool\n",
    "def code_explanation_agent(concept: str) -> str:\n",
    "    \"\"\"\n",
    "    Explains a given Python concept, function, keyword, or error message in detail.\n",
    "    Use this when the user asks for an explanation of something.\n",
    "    The output is raw explanation, which the Socratic agent will then use to ask questions.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM specialized in explanations.\n",
    "    # logger.info(f\"Executing Code Explanation for: {concept}\") # Uncomment when logger is ready\n",
    "    return f\"Explanation Result: The concept of '{concept}' in Python generally refers to [brief factual summary]. For instance, if it's about 'loops', it's about repetitive execution. If it's 'objects', it's about data and behavior bundling.\"\n",
    "\n",
    "@tool\n",
    "def challenge_generator_agent(topic: str, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a Python coding challenge or a fill-in-the-blanks exercise based on the specified topic and difficulty.\n",
    "    Use this when the user requests a challenge.\n",
    "    The output is the challenge, which the Socratic agent will present.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM or a challenge generation service.\n",
    "    # logger.info(f\"Executing Challenge Generation for: {topic}, Difficulty: {difficulty}\") # Uncomment when logger is ready\n",
    "    return f\"Challenge Result: For '{topic}' at '{difficulty}' difficulty: 'Write a Python function that takes a list of numbers and returns the sum of all **odd** numbers.' How would you approach solving this?\"\n",
    "\n",
    "@tool\n",
    "def mcq_agent(topic: str, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a multiple-choice question (MCQ) on a given Python topic and difficulty level.\n",
    "    The output will be a JSON string containing the question, options, and correct answer.\n",
    "    This tool is called when the Socratic agent decides to test understanding via MCQ.\n",
    "    \"\"\"\n",
    "    # In a real scenario, this would call another LLM specifically for MCQ generation.\n",
    "    # logger.info(f\"Executing MCQ Generation for: {topic}, Difficulty: {difficulty}\") # Uncomment when logger is ready\n",
    "    mcq_data = {\n",
    "        \"question\": f\"Which of the following operations would lead to an `IndentationError` in Python?\",\n",
    "        \"options\": [\"A) Missing a colon after a function definition\", \"B) Inconsistent use of spaces and tabs for indentation\", \"C) Using a reserved keyword as a variable name\", \"D) Forgetting a closing parenthesis\"],\n",
    "        \"correct_answer\": \"B\"\n",
    "    }\n",
    "    return json.dumps(mcq_data)\n",
    "\n",
    "# List of all user-facing tools\n",
    "user_facing_tools = [code_analysis_agent, code_explanation_agent, challenge_generator_agent, mcq_agent]\n",
    "\n",
    "# --- Define Internal Supervisor Tools (for routing decisions) ---\n",
    "# These are \"tools\" the supervisor LLM will call to indicate its routing decision.\n",
    "@tool\n",
    "def route_to_socratic_question(query: str = None) -> str:\n",
    "    \"\"\"Routes the conversation to the main Socratic Questioning agent for general teaching or follow-up.\n",
    "    This is the default route for general queries, concept discussions, and after tool outputs.\n",
    "    Optionally includes a follow-up query for the Socratic agent if the intent is specific.\n",
    "    \"\"\"\n",
    "    return \"socratic_question\"\n",
    "\n",
    "@tool\n",
    "def route_to_code_analysis(code: str) -> str:\n",
    "    \"\"\"Routes to the Code Analysis agent for debugging or code review. Requires the code snippet.\"\"\"\n",
    "    return \"code_analysis\"\n",
    "\n",
    "@tool\n",
    "def route_to_code_explanation(concept: str) -> str:\n",
    "    \"\"\"Routes to the Code Explanation agent to explain a specific concept, keyword, or error. Requires the concept.\"\"\"\n",
    "    return \"code_explanation\"\n",
    "\n",
    "@tool\n",
    "def route_to_challenge_generator(topic: str = None, difficulty: str = None) -> str:\n",
    "    \"\"\"Routes to the Challenge Generator agent to create a coding challenge. Optionally specify topic and difficulty.\"\"\"\n",
    "    return \"challenge_generator\"\n",
    "\n",
    "@tool\n",
    "def route_to_mcq_generator(topic: str = None, difficulty: str = None) -> str:\n",
    "    \"\"\"Routes to the MCQ Generator agent to create a multiple-choice question. Optionally specify topic and difficulty.\"\"\"\n",
    "    return \"mcq_generator\"\n",
    "\n",
    "# List of all internal routing tools available to the Supervisor\n",
    "supervisor_routing_tools = [\n",
    "    route_to_socratic_question,\n",
    "    route_to_code_analysis,\n",
    "    route_to_code_explanation,\n",
    "    route_to_challenge_generator,\n",
    "    route_to_mcq_generator\n",
    "]\n",
    "\n",
    "# Supervisor Agent Setup\n",
    "supervisor_system_prompt = \"\"\"\n",
    "You are a highly intelligent routing agent for a Socratic Python Tutor. Your task is to analyze\n",
    "the user's last message and the conversation history to determine the most appropriate next step\n",
    "in the learning process.\n",
    "\n",
    "You have access to several internal routing tools. Call exactly one of these tools to specify\n",
    "which specialized agent or flow should handle the user's request.\n",
    "\n",
    "Here are your routing rules:\n",
    "-   **Default:** For general questions, learning new topics, or continuing a Socratic dialogue, use `route_to_socratic_question`. This should be your most frequent choice.\n",
    "-   **Code Analysis:** If the user provides Python code and asks for debugging, feedback, review, or analysis, use `route_to_code_analysis` and pass the code.\n",
    "-   **Code Explanation:** If the user explicitly asks for an explanation of a specific Python concept, keyword, or error message, use `route_to_code_explanation` and pass the concept.\n",
    "-   **Challenge/Exercise:** If the user explicitly asks for a coding challenge, exercise, or fill-in-the-blanks, use `route_to_challenge_generator`.\n",
    "-   **MCQ:** If the user asks for a multiple-choice question or you determine an MCQ is a good way to test their understanding, use `route_to_mcq_generator`.\n",
    "\n",
    "Pay close attention to keywords and the overall intent. Your response MUST be a tool call.\n",
    "\n",
    "Current difficulty level: {difficulty_level}\n",
    "Current topic: {topic}\n",
    "Current sub-topic: {sub_topic}\n",
    "\"\"\"\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", supervisor_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "supervisor_runnable = supervisor_prompt | llm.bind_tools(supervisor_routing_tools)\n",
    "\n",
    "# Socratic Agent Setup (This is our main Socratic Questioning LLM)\n",
    "socratic_system_prompt = \"\"\"\n",
    "You are a Socratic Python programming tutor. Your goal is to guide the user to discover answers\n",
    "and understand concepts through thoughtful questions, rather than directly providing solutions.\n",
    "\n",
    "Here are your core principles:\n",
    "1.  **Ask Questions:** Always respond with a question, unless explicitly providing feedback on code or an MCQ answer.\n",
    "2.  **Socratic Method:** Break down complex problems into smaller, manageable questions.\n",
    "3.  **Encourage Exploration:** Prompt the user to experiment, research, or think critically.\n",
    "4.  **Adapt to User Understanding:**\n",
    "    * **Struggle Detection:** If the user seems confused, provides incorrect answers, or asks for direct solutions, simplify your questions, rephrase, or offer a hint.\n",
    "    * **Progression:** If the user demonstrates understanding, subtly move to a slightly more advanced sub-concept or a related new topic. Avoid repetitive questioning on the same point.\n",
    "5.  **Interpret Tool Outputs Socratically:** If a tool provides information (e.g., Code Analysis Result, Explanation Result, Challenge Result), your task is to *process that information* and turn it into a Socratic question or guided step for the user. Do not just relay the tool's output directly.\n",
    "6.  **Maintain Context:** Keep track of the current topic and sub-topic.\n",
    "7.  **Be Patient and Encouraging:** Foster a positive learning environment.\n",
    "8.  **ReAct Architecture (Internal Thought):** Before responding, articulate your thought process. Start your response with \"Thought: [Your reasoning here]\". This thought will be logged but not shown to the user. Then, proceed with your Socratic question.\n",
    "\n",
    "Current difficulty level: {difficulty_level}\n",
    "Current topic: {topic}\n",
    "Current sub-topic: {sub_topic}\n",
    "User struggle count: {user_struggle_count}\n",
    "MCQ active: {mcq_active}\n",
    "\"\"\"\n",
    "\n",
    "socratic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", socratic_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "socratic_agent_runnable = socratic_prompt | llm # Socratic agent does not call tools directly, supervisor does\n",
    "\n",
    "# --- 3. Define the Graph Nodes ---\n",
    "\n",
    "def call_supervisor(state: SocraticAgentState):\n",
    "    \"\"\"\n",
    "    Node for the supervisor to determine the next action/agent based on user intent.\n",
    "    \"\"\"\n",
    "    # logger.info(\"Supervisor node activated.\") # Uncomment when logger is ready\n",
    "    messages = state[\"messages\"][-MAX_MESSAGES_IN_CONTEXT:] # Apply truncation here\n",
    "    # Pass the full state to the prompt for contextual awareness in routing\n",
    "    response = supervisor_runnable.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"difficulty_level\": state[\"difficulty_level\"],\n",
    "        \"user_struggle_count\": state[\"user_struggle_count\"],\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"sub_topic\": state[\"sub_topic\"]\n",
    "    })\n",
    "\n",
    "    # The supervisor is expected to call one of its internal routing tools.\n",
    "    # Extract the tool call and set the next_node and tool_input in the state.\n",
    "    if response.tool_calls:\n",
    "        # Access tool name from the 'function' dict within the tool_call dictionary\n",
    "        # tool_call is a dictionary here, not a ToolCall object\n",
    "        tool_call_dict = response.tool_calls[0]\n",
    "        tool_name = tool_call_dict.get('function', {}).get('name')\n",
    "        tool_input = tool_call_dict.get('function', {}).get('arguments') # Arguments are also nested\n",
    "\n",
    "        # IMPORTANT: Add a check here if tool_name is None, indicating a malformed tool call\n",
    "        if tool_name is None:\n",
    "            print(\"Warning: Supervisor LLM returned a malformed tool call (name is None). Defaulting to socratic_question.\")\n",
    "            return {\"messages\": [response], \"next_node\": \"socratic_question\"}\n",
    "\n",
    "        next_node = tool_name.replace(\"route_to_\", \"\") # Extract node name (e.g., \"socratic_question\")\n",
    "        # logger.info(f\"Supervisor decided to route to: {next_node} with input: {tool_input}\") # Uncomment when logger is ready\n",
    "        return {\"messages\": [response], \"next_node\": next_node, \"tool_input\": tool_input}\n",
    "    else:\n",
    "        # Fallback if supervisor doesn't call a tool (shouldn't happen with proper prompt)\n",
    "        # Force it to the socratic question node\n",
    "        print(\"Warning: Supervisor LLM did not call a tool. Defaulting to socratic_question.\")\n",
    "        return {\"messages\": [response], \"next_node\": \"socratic_question\"}\n",
    "\n",
    "\n",
    "def socratic_question_node(state: SocraticAgentState):\n",
    "    \"\"\"\n",
    "    Node for the main Socratic LLM to ask questions or interpret tool outputs.\n",
    "    \"\"\"\n",
    "    # logger.info(\"Socratic Question Node activated.\") # Uncomment when logger is ready\n",
    "    messages = state[\"messages\"][-MAX_MESSAGES_IN_CONTEXT:] # Apply truncation here\n",
    "    response = socratic_agent_runnable.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"difficulty_level\": state[\"difficulty_level\"],\n",
    "        \"user_struggle_count\": state[\"user_struggle_count\"],\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"sub_topic\": state[\"sub_topic\"],\n",
    "        \"mcq_active\": state[\"mcq_active\"]\n",
    "    })\n",
    "\n",
    "    # Extract thought (for logging)\n",
    "    thought = \"\"\n",
    "    if response.content and response.content.startswith(\"Thought:\"):\n",
    "        parts = response.content.split(\"Thought:\", 1)\n",
    "        if len(parts) > 1:\n",
    "            thought = parts[1].strip().split('\\n', 1)[0]\n",
    "\n",
    "    return {\"messages\": [response], \"agent_thought\": thought}\n",
    "\n",
    "\n",
    "def call_specialized_tool_node(state: SocraticAgentState):\n",
    "    \"\"\"\n",
    "    Node to execute a specialized user-facing tool based on supervisor's decision.\n",
    "    \"\"\"\n",
    "    # logger.info(f\"Call Specialized Tool Node activated for {state['next_node']}\") # Uncomment when logger is ready\n",
    "    tool_name = state[\"next_node\"] # This comes from the supervisor's routing decision\n",
    "    tool_args = state[\"tool_input\"]\n",
    "\n",
    "    # Manually find and execute the tool function\n",
    "    tool_function = next((t for t in user_facing_tools if t.name == tool_name), None)\n",
    "\n",
    "    tool_output = \"\"\n",
    "    if tool_function:\n",
    "        try:\n",
    "            tool_output = tool_function(**tool_args)\n",
    "            # logger.info(f\"Tool '{tool_name}' executed. Output: {tool_output[:100]}...\") # Uncomment when logger is ready\n",
    "        except Exception as e:\n",
    "            tool_output = f\"Error executing tool {tool_name}: {e}\"\n",
    "            # logger.error(f\"Error executing tool {tool_name}: {e}\", exc_info=True) # Uncomment when logger is ready\n",
    "    else:\n",
    "        tool_output = f\"Error: Specialized tool '{tool_name}' not found.\"\n",
    "        # logger.error(f\"Specialized tool '{tool_name}' not found.\") # Uncomment when logger is ready\n",
    "\n",
    "    # Add the tool output as a ToolMessage to the conversation history\n",
    "    # The socratic_question_node will then process this and ask a question.\n",
    "    # Provide a unique tool_call_id for the ToolMessage\n",
    "    return {\"messages\": [ToolMessage(content=tool_output, name=tool_name, tool_call_id=str(uuid.uuid4()))]}\n",
    "\n",
    "\n",
    "def generate_mcq_node(state: SocraticAgentState):\n",
    "    \"\"\"\n",
    "    Node specifically for generating an MCQ via the mcq_agent tool.\n",
    "    This also handles setting the MCQ active state for main.py.\n",
    "    \"\"\"\n",
    "    # logger.info(\"MCQ Generation Node activated.\") # Uncomment when logger is ready\n",
    "    tool_name = state[\"next_node\"] # This comes from the supervisor's routing decision\n",
    "    tool_args = state[\"tool_input\"] # Should contain topic and difficulty from supervisor\n",
    "\n",
    "    tool_function = next((t for t in user_facing_tools if t.name == tool_name), None)\n",
    "    mcq_raw_output = \"\"\n",
    "\n",
    "    if tool_function:\n",
    "        try:\n",
    "            mcq_raw_output = tool_function(**tool_args)\n",
    "            mcq_data = json.loads(mcq_raw_output)\n",
    "            state[\"mcq_active\"] = True\n",
    "            state[\"mcq_question\"] = mcq_data[\"question\"]\n",
    "            state[\"mcq_options\"] = mcq_data[\"options\"]\n",
    "            state[\"mcq_correct_answer\"] = mcq_data[\"correct_answer\"]\n",
    "            # logger.info(\"MCQ details updated in state.\") # Uncomment when logger is ready\n",
    "        except Exception as e:\n",
    "            mcq_raw_output = f\"Error generating MCQ: {e}\"\n",
    "            # logger.error(f\"Error generating MCQ: {e}\", exc_info=True) # Uncomment when logger is ready\n",
    "    \n",
    "    # Add a ToolMessage for the MCQ generation, which the Socratic LLM can interpret\n",
    "    # or simply for logging purposes in the graph flow.\n",
    "    # Provide a unique tool_call_id for the ToolMessage\n",
    "    return {\"messages\": [ToolMessage(content=mcq_raw_output, name=tool_name, tool_call_id=str(uuid.uuid4()))], **state}\n",
    "\n",
    "\n",
    "# --- 4. Define the Graph Edges (Conditional Logic) ---\n",
    "\n",
    "def route_supervisor_output(state: SocraticAgentState):\n",
    "    \"\"\"\n",
    "    Conditional edge from the supervisor to determine the next node based on its decision.\n",
    "    \"\"\"\n",
    "    # logger.info(f\"Routing supervisor output. Next node: {state['next_node']}\") # Uncomment when logger is ready\n",
    "    if state[\"next_node\"] == \"socratic_question\":\n",
    "        return \"socratic_question_node\"\n",
    "    elif state[\"next_node\"] == \"mcq_generator\":\n",
    "        return \"generate_mcq_node\"\n",
    "    # All other specialized tools go through the generic tool calling node\n",
    "    elif state[\"next_node\"] in [\"code_analysis\", \"code_explanation\", \"challenge_generator\"]:\n",
    "        return \"call_specialized_tool_node\"\n",
    "    return \"socratic_question_node\" # Fallback to socratic question if unexpected\n",
    "\n",
    "\n",
    "# --- 5. Build the LangGraph ---\n",
    "\n",
    "# Create a StateGraph instance with our defined state.\n",
    "workflow = StateGraph(SocraticAgentState)\n",
    "\n",
    "# Add nodes to the workflow.\n",
    "workflow.add_node(\"call_supervisor\", call_supervisor)\n",
    "workflow.add_node(\"socratic_question_node\", socratic_question_node) # Renamed from call_llm\n",
    "workflow.add_node(\"call_specialized_tool_node\", call_specialized_tool_node)\n",
    "workflow.add_node(\"generate_mcq_node\", generate_mcq_node)\n",
    "\n",
    "# Set the entry point for the graph.\n",
    "workflow.set_entry_point(\"call_supervisor\")\n",
    "\n",
    "# Define the edges.\n",
    "# From supervisor, route conditionally\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_supervisor\",\n",
    "    route_supervisor_output,\n",
    "    {\n",
    "        \"socratic_question_node\": \"socratic_question_node\",\n",
    "        \"call_specialized_tool_node\": \"call_specialized_tool_node\",\n",
    "        \"generate_mcq_node\": \"generate_mcq_node\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# After a specialized tool (other than MCQ), return to the socratic_question_node\n",
    "# for the Socratic LLM to interpret the tool's output and formulate a question.\n",
    "workflow.add_edge(\"call_specialized_tool_node\", \"socratic_question_node\")\n",
    "\n",
    "# After the socratic_question_node, the run ends. The main.py loop will then take user input.\n",
    "workflow.add_edge(\"socratic_question_node\", END)\n",
    "\n",
    "# After generating an MCQ, the run ends. Main.py handles the MCQ display and user input.\n",
    "workflow.add_edge(\"generate_mcq_node\", END)\n",
    "\n",
    "# Removed MemorySaver initialization and compilation\n",
    "# checkpointer = MemorySaver()\n",
    "socratic_graph = workflow.compile() # Compile without checkpointer\n",
    "\n",
    "# --- Temporary LLM Connection Test ---\n",
    "# This function will be called once when the module is imported to test LLM connectivity.\n",
    "def _test_llm_connection():\n",
    "    print(\"\\n--- Testing LLM Connection (Temporary) ---\")\n",
    "    try:\n",
    "        test_message = HumanMessage(content=\"Say hi!\")\n",
    "        response = llm.invoke([test_message])\n",
    "        print(f\"LLM Test Response: {response.content}\")\n",
    "        print(\"LLM connection successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Connection Test FAILED: {e}\")\n",
    "        print(\"Please check your GOOGLE_API_KEY and network connection.\")\n",
    "    print(\"--- End LLM Connection Test ---\\n\")\n",
    "\n",
    "# --- Temporary Node Functionality Test ---\n",
    "# This function allows testing individual nodes with a sample state.\n",
    "def _test_node_functionality(node_name: str, initial_state: SocraticAgentState):\n",
    "    print(f\"\\n--- Testing Node: {node_name} ---\")\n",
    "    try:\n",
    "        # Get the node function from the workflow's nodes\n",
    "        # Access the runnable attribute to get the actual function\n",
    "        node_runnable = workflow.nodes[node_name].runnable\n",
    "\n",
    "        # Invoke the node's runnable with the provided initial state\n",
    "        result_state_update = node_runnable.invoke(initial_state)\n",
    "\n",
    "\n",
    "        print(f\"Node '{node_name}' executed successfully.\")\n",
    "        print(f\"Initial State (messages only): {[msg.content if hasattr(msg, 'content') else str(msg) for msg in initial_state['messages']]}\")\n",
    "        print(f\"Resulting State Update: {result_state_update}\")\n",
    "\n",
    "        # For nodes that return messages, let's print them\n",
    "        if 'messages' in result_state_update and result_state_update['messages']:\n",
    "            print(\"Messages returned by node:\")\n",
    "            for msg in result_state_update['messages']:\n",
    "                if isinstance(msg, BaseMessage):\n",
    "                    print(f\"  - Type: {msg.type}, Content: {msg.content[:50]}...\")\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        # Ensure tool_calls are correctly converted to ToolCall objects\n",
    "                        for tc in msg.tool_calls:\n",
    "                            if isinstance(tc, ToolCall):\n",
    "                                print(f\"    Tool Call: {tc.function.name} with args {tc.function.arguments}\")\n",
    "                            else:\n",
    "                                # Fallback for debugging if it's still a dict\n",
    "                                print(f\"    Raw Tool Call (still dict?): {tc}\")\n",
    "                                print(f\"    Attempting dict access: Name={tc.get('function', {}).get('name')}, Args={tc.get('function', {}).get('arguments')}\")\n",
    "                else:\n",
    "                    print(f\"  - Raw: {msg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Node '{node_name}' Test FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for node errors\n",
    "    print(f\"--- End Node Test: {node_name} ---\\n\")\n",
    "\n",
    "\n",
    "# Call the LLM connection test immediately when this module is loaded\n",
    "_test_llm_connection()\n",
    "\n",
    "# Example usage of the new node testing function (uncomment to test specific nodes)\n",
    "# Ensure your GOOGLE_API_KEY is set for LLM-based nodes.\n",
    "\n",
    "# Test call_supervisor node\n",
    "# sample_supervisor_state = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"I need help with debugging this code: print('hello')\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Python Basics\",\n",
    "#     sub_topic=\"Introduction\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\", next_node=\"\", tool_input={}\n",
    "# )\n",
    "# _test_node_functionality(\"call_supervisor\", sample_supervisor_state)\n",
    "\n",
    "# Test socratic_question_node\n",
    "# sample_socratic_state = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"What are variables?\"), AIMessage(content=\"Thought: User asked about variables. I should ask a foundational question. What is your current understanding of variables in programming?\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Variables\",\n",
    "#     sub_topic=\"Definition\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\", next_node=\"\", tool_input={}\n",
    "# )\n",
    "# _test_node_functionality(\"socratic_question_node\", sample_socratic_state)\n",
    "\n",
    "# Test call_specialized_tool_node (e.g., code_analysis)\n",
    "# This requires the supervisor to have set next_node and tool_input previously.\n",
    "# For a direct test, we simulate that state.\n",
    "# sample_tool_state_code_analysis = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"debug this code: print('hello')\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "    # user_struggle_count=0,\n",
    "#     topic=\"Debugging\",\n",
    "#     sub_topic=\"Code Analysis\",\n",
    "#     mcq_active=False,\n",
    "#     mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\",\n",
    "#     next_node=\"code_analysis\", # Supervisor would set this\n",
    "#     tool_input={\"code\": \"def my_func():\\n    pass\"} # Supervisor would set this\n",
    "# )\n",
    "# _test_node_functionality(\"call_specialized_tool_node\", sample_tool_state_code_analysis)\n",
    "\n",
    "# Test generate_mcq_node\n",
    "# sample_mcq_state = SocraticAgentState(\n",
    "#     messages=[HumanMessage(content=\"Give me an MCQ on functions.\")],\n",
    "#     difficulty_level=\"beginner\",\n",
    "#     user_struggle_count=0,\n",
    "#     topic=\"Functions\",\n",
    "#     sub_topic=\"MCQ\",\n",
    "#     mcq_active=False,\n",
    "    # mcq_question=\"\", mcq_options=[], mcq_correct_answer=\"\",\n",
    "#     agent_thought=\"\",\n",
    "#     next_node=\"mcq_generator\", # Supervisor would set this\n",
    "#     tool_input={\"topic\": \"functions\", \"difficulty\": \"beginner\"} # Supervisor would set this\n",
    "# )\n",
    "# _test_node_functionality(\"generate_mcq_node\", sample_mcq_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f761cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115579d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2290ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from socratic_bot_logic import SocraticBot\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from config import load_environment_variables\n",
    "from logger import setup_logging\n",
    "\n",
    "def main():\n",
    "# Set up logging and configuration\n",
    "# logger = setup_logging()\n",
    "# google_api_key = load_environment_variables()\n",
    "\n",
    "# Create the SocraticBot instance\n",
    "bot = SocraticBot()\n",
    "\n",
    "# Set an initial topic (for example, variables in Python)\n",
    "initial_topic = \"variables in Python\"\n",
    "bot.update_current_topic(initial_topic)\n",
    "welcome_message = f\"Hello! I'm your Socratic Python Tutor. Today, we can start with '{initial_topic}'.\"\n",
    "print(f\"Bot: {welcome_message}\")\n",
    "bot.add_message_to_history(AIMessage(content=welcome_message))\n",
    "\n",
    "# Present options to the user\n",
    "options_message = (\"\\nBot: Would you like to:\\n\"\n",
    "\"1. Test your knowledge on variables in Python?\\n\"\n",
    "\"2. Learn more about variables in Python?\\n\"\n",
    "\"Please type '1' or '2'.\")\n",
    "print(options_message)\n",
    "\n",
    "# Main interaction loop\n",
    "while True:\n",
    "user_input = input(\"You: \").strip()\n",
    "logger.info(f\"User: {user_input}\")\n",
    "\n",
    "# Exit condition\n",
    "if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "print(\"Bot: Goodbye! Keep coding!\")\n",
    "logger.info(\"User exited the session.\")\n",
    "break\n",
    "\n",
    "# A simple routing logic: if the input contains code indicators, use code_analysis\n",
    "if \"def \" in user_input or \"print(\" in user_input:\n",
    "# Let the tool analyze the code first\n",
    "analysis_feedback = bot.tools[\"code_analysis_tool\"](user_input)\n",
    "print(f\"Bot (Code Analysis): {analysis_feedback}\")\n",
    "logger.info(f\"Bot (Code Analysis): {analysis_feedback}\")\n",
    "# Follow up with a Socratic question based on the feedback\n",
    "follow_up_q = \"Based on the code analysis, what do you think might be improved?\"\n",
    "print(f\"Bot: {follow_up_q}\")\n",
    "bot.add_message_to_history(AIMessage(content=follow_up_q))\n",
    "continue\n",
    "\n",
    "# If the input asks for an explanation (e.g., 'what is sort()' or similar), use code_explanation\n",
    "if \"explain\" in user_input.lower() or \"what is\" in user_input.lower():\n",
    "explanation = bot.tools[\"code_explanation_tool\"](user_input)\n",
    "print(f\"Bot (Explanation): {explanation}\")\n",
    "logger.info(f\"Bot (Explanation): {explanation}\")\n",
    "# Return to Socratic mode after giving the explanation\n",
    "socratic_follow_up = \"Can you tell me how this explanation might help you fix an issue in your code?\"\n",
    "print(f\"Bot: {socratic_follow_up}\")\n",
    "bot.add_message_to_history(AIMessage(content=socratic_follow_up))\n",
    "continue\n",
    "\n",
    "# Otherwise, use the general LLM flow for Socratic reasoning:\n",
    "bot.add_message_to_history(HumanMessage(content=user_input))\n",
    "response = bot.send_message_to_llm(user_input)\n",
    "print(f\"Bot: {response}\")\n",
    "logger.info(f\"Bot: {response}\")\n",
    "bot.add_message_to_history(AIMessage(content=response))\n",
    "if name == \"main\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da726105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f40ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ad35d99e270>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the system prompt for the Socratic Agent.\n",
    "# This prompt guides the LLM's behavior, making it act as a Socratic tutor, detecting struggle, adapting difficulty, and using tools.\n",
    "socratic_system_prompt = \"\"\"\n",
    "You are a friendly Socratic Python programming tutor. Your goal is to guide the user to discover answers\n",
    "and understand concepts through thoughtful questions, rather than directly providing solutions. \n",
    "The user may provide code snippets that needs to be debugged. Help the user to debug and understand the code by calling the appropriate tool agents.\n",
    "\n",
    "Here are your core principles:\n",
    "1.  **Ask Questions:** Always respond with a question, unless explicitly providing feedback on code or an MCQ answer.\n",
    "2.  **Socratic Method:** Break down complex problems into smaller, manageable questions.\n",
    "3.  **Encourage Exploration:** Prompt the user to experiment, research, or think critically.\n",
    "4.  **Adapt to User Understanding:**\n",
    "    * **Struggle Detection:** If the user seems confused, provides incorrect answers, or asks for direct solutions, simplify your questions, rephrase, or offer a hint. You can also suggest taking a multiple-choice question (MCQ) to assess their understanding differently.\n",
    "    * **Progression:** If the user demonstrates understanding, subtly move to a slightly more advanced sub-concept or a related new topic. Avoid repetitive questioning on the same point.\n",
    "5.  **Tool Usage:** You have access to several specialized tools. Use them judiciously based on the user's query:\n",
    "    * `code_analysis_agent`: Use this when the user provides Python code and asks for feedback, debugging, or analysis.\n",
    "    * `code_explanation_agent`: Use this when the user asks for an explanation of a Python concept, function, keyword, or error message.\n",
    "    * `challenge_generator_agent`: Use this when the user wants a coding challenge or a fill-in-the-blanks exercise.\n",
    "    * `mcq_agent`: Use this when you want to generate a multiple-choice question to test the user's understanding, especially if they are struggling or you want to quickly assess a concept.\n",
    "6.  **Maintain Context:** Keep track of the current topic and sub_topic.\n",
    "7.  **Be Patient and Encouraging:** Foster a positive learning environment.\n",
    "8.  **ReAct Architecture:** Before responding or calling a tool, always articulate your thought process. Start your response with \"Thought: [Your reasoning here]\". Then, proceed with your question or tool call. If you are calling a tool, the tool call should follow your thought. If you are directly asking a question, the question should follow your thought.\n",
    "\n",
    "Current difficulty level: {difficulty_level}\n",
    "Current topic: {topic}\n",
    "Current sub_topic: {sub_topic}\n",
    "User struggle count: {user_struggle_count}\n",
    "MCQ active: {mcq_active}\n",
    "\n",
    "Begin the conversation by asking the user what Python topic they'd like to learn or practice, or if they'd like to test their knowledge.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515ffa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
